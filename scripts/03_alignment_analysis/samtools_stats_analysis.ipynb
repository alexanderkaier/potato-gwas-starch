{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from the stats files of the alignment of all 192 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the function 'getFilePath' to get the paths of all desired files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilePath(path = '../../analysis/alignment_data_GWAS'):\n",
    "    '''\n",
    "    This function takes a path, removes the \"here\" path (\"./.\" in linux) from it and returns a list containing the \n",
    "    absolute path of all 'samtools stats' output files within that path.\n",
    "    '''\n",
    "    pathList = []\n",
    "    for root, subfolder, file in os.walk(path):\n",
    "        # Excluding the \"here\" path ('.'). It is important to not execute the script from a path with\n",
    "        # different relative distance to the target path to not fail expected path depth\n",
    "        if root.count(os.sep) == 4:\n",
    "            # Concatenating the sample paths and the samtools stats output file\n",
    "            pathList.append(os.path.join(os.path.abspath(root), file[2]))\n",
    "    return pathList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation and filling of data frame for original BAM files by looping over all stat files and extracting indices and sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "#                           #\n",
    "# Creating empty data frame #\n",
    "#                           #\n",
    "#############################\n",
    "\n",
    "# Creating a list of absolute paths with 50 entries, one for each sample stat output file\n",
    "fileList = getFilePath(path = '../../analysis/alignment_data_GWAS')\n",
    "# Initialize sample index list\n",
    "sampleList = []\n",
    "# Initialize column name list\n",
    "nameArray = []\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for file in fileList:\n",
    "    # Extraction of sample name as for checking data frame entry validity\n",
    "    sampleList.append(file.split('/')[-2])\n",
    "    \n",
    "    # Extracting summary statistics for each sample\n",
    "    #SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = SN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    SN = SN.split('\\n')\n",
    "    for i in range(len(SN)):\n",
    "        SN[i] = SN[i].split('\\t')\n",
    "    del(SN[-1])\n",
    "    \n",
    "    # Filling column name list (happens only in first loop)\n",
    "    if len(nameArray)==0:\n",
    "        for i in range(len(SN)):\n",
    "            # Extracting column names (also deleting leading and tailing whitespaces and replacing spaces with underscores)\n",
    "            nameArray.append(SN[i][0])\n",
    "            nameArray[i] = re.sub(r\"[^\\w\\s]\", '', nameArray[i])\n",
    "            nameArray[i] = nameArray[i].strip()\n",
    "            nameArray[i] = re.sub(r\"\\s+\", '_', nameArray[i])\n",
    "\n",
    "# Creation of empty data frame\n",
    "    statFrame = pd.DataFrame(index=sampleList, columns=nameArray)\n",
    "\n",
    "\n",
    "##########################\n",
    "#                        #\n",
    "# Filling the data frame #\n",
    "#                        #\n",
    "##########################\n",
    "\n",
    "# Defining path to stat files\n",
    "bamPath = '../../analysis/alignment_data_GWAS'\n",
    "\n",
    "# Creating a list of absolute paths with 192 entries\n",
    "bamList = getFilePath(path = bamPath)\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for i in range(len(bamList)):\n",
    "    # Extraction of sample name as index identifier for filling in values\n",
    "    sample = bamList[i].split('/')[-2]\n",
    "    \n",
    "    # Extracting summary statistics\n",
    "    # bam mem alignment stat file summary\n",
    "    bamSN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(bamList[i])], shell=True) # Extracting summary data for whole alignment\n",
    "    bamSN = bamSN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    bamSN = bamSN.split('\\n')\n",
    "    \n",
    "    for i in range(len(bamSN)):\n",
    "        bamSN[i] = bamSN[i].split('\\t')\n",
    "    del(bamSN[-1])\n",
    "    \n",
    "    # Extracting specific values \n",
    "    bamValArray = np.array([])\n",
    "    for i in range(len(bamSN)):\n",
    "        bamValArray = np.append(bamValArray, bamSN[i][1])\n",
    "    \n",
    "    # Filling in data frame\n",
    "    statFrame.loc[sample] = bamValArray\n",
    "\n",
    "\n",
    "#########################\n",
    "#                       #\n",
    "# Saving the data frame #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "# Save data frame to csv file for plotting in R    \n",
    "outPath = os.path.abspath('../../analysis/alignment_data_GWAS/summary_table.csv')\n",
    "statFrame.to_csv(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation and filling of data frame for duplicate marked BAM files by looping over all stat files and extracting indices and sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                                                                            #\n",
    "# Redefining the stats path function for catching the right file in the path #\n",
    "#                                                                            #\n",
    "##############################################################################\n",
    "\n",
    "def getFilePath(path = '../../analysis/alignment_data_GWAS'):\n",
    "    '''\n",
    "    This function takes a path, removes the \"here\" path (\"./.\" in linux) from it and returns a list containing the \n",
    "    absolute path of all 'samtools stats' output files within that path.\n",
    "    '''\n",
    "    pathList = []\n",
    "    for root, subfolder, file in os.walk(path):\n",
    "        # Excluding the \"here\" path ('.'). It is important to not execute the script from a path with\n",
    "        # different relative distance to the target path to not fail expected path depth\n",
    "        if root.count(os.sep) == 4:\n",
    "            # Concatenating the sample paths and the samtools stats output file\n",
    "            pathList.append(os.path.join(os.path.abspath(root), file[5]))\n",
    "    return pathList\n",
    "\n",
    "\n",
    "#############################\n",
    "#                           #\n",
    "# Creating empty data frame #\n",
    "#                           #\n",
    "#############################\n",
    "\n",
    "# Creating a list of absolute paths with 50 entries, one for each sample stat output file\n",
    "fileList = getFilePath(path = '../../analysis/alignment_data_markeddup')\n",
    "# Initialize sample index list\n",
    "sampleList = []\n",
    "# Initialize column name list\n",
    "nameArray = []\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for file in fileList:\n",
    "    # Extraction of sample name as for checking data frame entry validity\n",
    "    sampleList.append(file.split('/')[-2])\n",
    "    \n",
    "    # Extracting summary statistics for each sample\n",
    "    #SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = SN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    SN = SN.split('\\n')\n",
    "    for i in range(len(SN)):\n",
    "        SN[i] = SN[i].split('\\t')\n",
    "    del(SN[-1])\n",
    "    \n",
    "    # Filling column name list (happens only in first loop)\n",
    "    if len(nameArray)==0:\n",
    "        for i in range(len(SN)):\n",
    "            # Extracting column names (also deleting leading and tailing whitespaces and replacing spaces with underscores)\n",
    "            nameArray.append(SN[i][0])\n",
    "            nameArray[i] = re.sub(r\"[^\\w\\s]\", '', nameArray[i])\n",
    "            nameArray[i] = nameArray[i].strip()\n",
    "            nameArray[i] = re.sub(r\"\\s+\", '_', nameArray[i])\n",
    "\n",
    "# Creation of empty data frame\n",
    "    statFrame = pd.DataFrame(index=sampleList, columns=nameArray)\n",
    "\n",
    "\n",
    "##########################\n",
    "#                        #\n",
    "# Filling the data frame #\n",
    "#                        #\n",
    "##########################\n",
    "\n",
    "# Defining path to stat files\n",
    "bamPath = '../../analysis/alignment_data_markeddup'\n",
    "\n",
    "# Creating a list of absolute paths with 192 entries\n",
    "bamList = getFilePath(path = bamPath)\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for i in range(len(bamList)):\n",
    "    # Extraction of sample name as index identifier for filling in values\n",
    "    sample = bamList[i].split('/')[-2]\n",
    "    \n",
    "    # Extracting summary statistics\n",
    "    # bam mem alignment stat file summary\n",
    "    bamSN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(bamList[i])], shell=True) # Extracting summary data for whole alignment\n",
    "    bamSN = bamSN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    bamSN = bamSN.split('\\n')\n",
    "    \n",
    "    for i in range(len(bamSN)):\n",
    "        bamSN[i] = bamSN[i].split('\\t')\n",
    "    del(bamSN[-1])\n",
    "    \n",
    "    # Extracting specific values \n",
    "    bamValArray = np.array([])\n",
    "    for i in range(len(bamSN)):\n",
    "        bamValArray = np.append(bamValArray, bamSN[i][1])\n",
    "    \n",
    "    # Filling in data frame\n",
    "    statFrame.loc[sample] = bamValArray\n",
    "\n",
    "\n",
    "#########################\n",
    "#                       #\n",
    "# Saving the data frame #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "# Save data frame to csv file for plotting in R    \n",
    "outPath = os.path.abspath('../../analysis/alignment_data_markeddup/summary_table_markeddup.csv')\n",
    "statFrame.to_csv(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation and filling of data frame for duplicate removed BAM files by looping over all stat files and extracting indices and sample names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#                                                                            #\n",
    "# Redefining the stats path function for catching the right file in the path #\n",
    "#                                                                            #\n",
    "##############################################################################\n",
    "\n",
    "def getFilePath(path = '../../analysis/alignment_data_GWAS'):\n",
    "    '''\n",
    "    This function takes a path, removes the \"here\" path (\"./.\" in linux) from it and returns a list containing the \n",
    "    absolute path of all 'samtools stats' output files within that path.\n",
    "    '''\n",
    "    pathList = []\n",
    "    for root, subfolder, file in os.walk(path):\n",
    "        # Excluding the \"here\" path ('.'). It is important to not execute the script from a path with\n",
    "        # different relative distance to the target path to not fail expected path depth\n",
    "        if root.count(os.sep) == 4:\n",
    "            # Concatenating the sample paths and the samtools stats output file\n",
    "            pathList.append(os.path.join(os.path.abspath(root), file[6]))\n",
    "    return pathList\n",
    "\n",
    "\n",
    "#############################\n",
    "#                           #\n",
    "# Creating empty data frame #\n",
    "#                           #\n",
    "#############################\n",
    "\n",
    "# Creating a list of absolute paths with 50 entries, one for each sample stat output file\n",
    "fileList = getFilePath(path = '../../analysis/alignment_data_markeddup')\n",
    "# Initialize sample index list\n",
    "sampleList = []\n",
    "# Initialize column name list\n",
    "nameArray = []\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for file in fileList:\n",
    "    # Extraction of sample name as for checking data frame entry validity\n",
    "    sampleList.append(file.split('/')[-2])\n",
    "    \n",
    "    # Extracting summary statistics for each sample\n",
    "    #SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(file)], shell=True) # Extracting summary data for whole alignment\n",
    "    SN = SN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    SN = SN.split('\\n')\n",
    "    for i in range(len(SN)):\n",
    "        SN[i] = SN[i].split('\\t')\n",
    "    del(SN[-1])\n",
    "    \n",
    "    # Filling column name list (happens only in first loop)\n",
    "    if len(nameArray)==0:\n",
    "        for i in range(len(SN)):\n",
    "            # Extracting column names (also deleting leading and tailing whitespaces and replacing spaces with underscores)\n",
    "            nameArray.append(SN[i][0])\n",
    "            nameArray[i] = re.sub(r\"[^\\w\\s]\", '', nameArray[i])\n",
    "            nameArray[i] = nameArray[i].strip()\n",
    "            nameArray[i] = re.sub(r\"\\s+\", '_', nameArray[i])\n",
    "\n",
    "# Creation of empty data frame\n",
    "    statFrame = pd.DataFrame(index=sampleList, columns=nameArray)\n",
    "\n",
    "\n",
    "##########################\n",
    "#                        #\n",
    "# Filling the data frame #\n",
    "#                        #\n",
    "##########################\n",
    "\n",
    "# Defining path to stat files\n",
    "bamPath = '../../analysis/alignment_data_markeddup'\n",
    "\n",
    "# Creating a list of absolute paths with 192 entries\n",
    "bamList = getFilePath(path = bamPath)\n",
    "\n",
    "# Looping over files and extracting summary statistics\n",
    "for i in range(len(bamList)):\n",
    "    # Extraction of sample name as index identifier for filling in values\n",
    "    sample = bamList[i].split('/')[-2]\n",
    "    \n",
    "    # Extracting summary statistics\n",
    "    # bam mem alignment stat file summary\n",
    "    bamSN = subprocess.check_output(['grep ^SN {} | cut -f 2-'.format(bamList[i])], shell=True) # Extracting summary data for whole alignment\n",
    "    bamSN = bamSN.decode('utf-8') # Decoding byte string into UTF-8 character string\n",
    "    bamSN = bamSN.split('\\n')\n",
    "    \n",
    "    for i in range(len(bamSN)):\n",
    "        bamSN[i] = bamSN[i].split('\\t')\n",
    "    del(bamSN[-1])\n",
    "    \n",
    "    # Extracting specific values \n",
    "    bamValArray = np.array([])\n",
    "    for i in range(len(bamSN)):\n",
    "        bamValArray = np.append(bamValArray, bamSN[i][1])\n",
    "    \n",
    "    # Filling in data frame\n",
    "    statFrame.loc[sample] = bamValArray\n",
    "\n",
    "\n",
    "#########################\n",
    "#                       #\n",
    "# Saving the data frame #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "# Save data frame to csv file for plotting in R    \n",
    "outPath = os.path.abspath('../../analysis/alignment_data_markeddup/summary_table_removeddup.csv')\n",
    "statFrame.to_csv(outPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the function 'samStatsDataFrame' to create a pandas Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function, to create a pandas Data Frame from the SN data of the'samtool stats' \n",
    "def samStatsDataFrame(path = '../../analysis/alignment_data/bwa-mem'):\n",
    "    '''\n",
    "    Function for creating a pandas Data Frame\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting coverage data produced with MultiQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rna/NEOPHOCA/GWAS/analysis/raw_seqs/multiqc_data/multiqc_general_stats.txt\n"
     ]
    }
   ],
   "source": [
    "path = '../../analysis/raw_seqs/multiqc_data/multiqc_general_stats.txt'\n",
    "absPath = os.path.abspath(path)\n",
    "print(absPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "covFrame = pd.read_csv(absPath, delimiter='\\t')\n",
    "#covFrame = covFrame.iloc[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(covFrame.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "covFrameSorted = covFrame.sort_values(by=[list(covFrame.columns)[4], list(covFrame.columns)[3]], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "covFrameSorted = covFrameSorted.drop(columns = ['FastQC_mqc-generalstats-fastqc-avg_sequence_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covFrameSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(covFrameSorted['FastQC_mqc-generalstats-fastqc-total_sequences'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
