{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import csv\n",
    "import os\n",
    "from BCBio import GFF\n",
    "from BCBio.GFF import GFFExaminer\n",
    "import pprint\n",
    "import gffpandas.gffpandas as gffpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for truncating floats\n",
    "def truncate(f, n):\n",
    "    '''Truncates/pads a float f to n decimal places without rounding'''\n",
    "    s = '{}'.format(f)\n",
    "    if 'e' in s or 'E' in s:\n",
    "        return '{0:.{1}f}'.format(f, n)\n",
    "    i, p, d = s.partition('.')\n",
    "    inter = '.'.join([i, (d+'0'*n)[:n]])\n",
    "    return(float(inter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LD for each chromosome in a named tuple, according to [Sharma et al., 2018] (https://doi.org/10.1534/g3.118.200377)\n",
    "LDs = {\"chr01\": 0.89,\n",
    "       \"chr02\": 1.05,\n",
    "       \"chr03\": 1.14,\n",
    "       \"chr04\": 0.86,\n",
    "       \"chr05\": 0.70,\n",
    "       \"chr06\": 1.11,\n",
    "       \"chr07\": 0.82,\n",
    "       \"chr08\": 0.93,\n",
    "       \"chr09\": 0.67,\n",
    "       \"chr10\": 0.96,\n",
    "       \"chr11\": 0.71,\n",
    "       \"chr12\": 0.66}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing stuff on the model of interest\n",
    "\n",
    "# Relative input string for the pandas module\n",
    "relPathString = \"../../data/GWAS_results/\"\n",
    "path = relPathString + \"scoresGen.csv\"\n",
    "\n",
    "inPathString = pathlib.Path(path)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "#scoreSortedAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "#scoreSortedRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoreFrame.head(n = 10), '\\n')\n",
    "#print(scoreSortedAlt.head(n = 10), '\\n')\n",
    "#print(scoreSortedRef.head(n = 10), '\\n')\n",
    "scoreFrameBest = scoreFrame.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreFrameAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "scoreFrameRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)\n",
    "print(scoreFrameAlt.head(n = 10), '\\n')\n",
    "print(scoreFrameRef.head(n = 10), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreSortedAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "scoreSortedRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)\n",
    "# Check for lowest score between REF and ALT scores\n",
    "if truncate(scoreSortedAlt.iloc[4, 5],2) < truncate(scoreSortedRef.iloc[4, 6],2):\n",
    "    bestTenThresh = truncate((scoreSortedAlt.iloc[4, 5] + scoreSortedAlt.iloc[5, 5])/2, 2)\n",
    "else:\n",
    "    bestTenThresh = truncate((scoreSortedRef.iloc[4, 6] + scoreSortedRef.iloc[5, 6])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreSortedRef.columns)[5][:5]} model: {bestTenThresh}\")\n",
    "bestList = scoreSortedAlt.iloc[:5,0].append(scoreSortedRef.iloc[:5,0])\n",
    "bestListTemplate = scoreSortedAlt.iloc[:5].append(scoreSortedRef.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestListTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining and saving the 10 best SNPs per model and their associated LD SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#                                          #\n",
    "# Reading the score files for all 6 models #\n",
    "#                                          #\n",
    "############################################\n",
    "\n",
    "# Relative input string for the pandas module\n",
    "relPathString = \"../../data/GWAS_results/\"\n",
    "pathAdd = relPathString + \"scoresAdd.csv\"\n",
    "pathOne = relPathString + \"scoresOne.csv\"\n",
    "pathTwo = relPathString + \"scoresTwo.csv\"\n",
    "pathDipGen = relPathString + \"scoresDipGen.csv\"\n",
    "pathDipAdd = relPathString + \"scoresDipAdd.csv\"\n",
    "pathGen = relPathString + \"scoresGen.csv\"\n",
    "\n",
    "\n",
    "#########################\n",
    "#                       #\n",
    "# Defining output paths #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "# Defining path for best scoring SNPs output\n",
    "relSNPPath = \"../../analysis/GWAS_results/\"\n",
    "pathSNPAdd = relSNPPath + \"bestSNPsAdd.csv\"\n",
    "pathSNPOne = relSNPPath + \"bestSNPsOne.csv\"\n",
    "pathSNPTwo = relSNPPath + \"bestSNPsTwo.csv\"\n",
    "pathSNPDipGen = relSNPPath + \"bestSNPsDipGen.csv\"\n",
    "pathSNPDipAdd = relSNPPath + \"bestSNPsDipAdd.csv\"\n",
    "pathSNPGen = relSNPPath + \"bestSNPsGen.csv\"\n",
    "\n",
    "# Defining path for LD coupled best scoring SNPs output\n",
    "relLDSNPPath = \"../../analysis/GWAS_results/\"\n",
    "pathLDSNPAdd = relSNPPath + \"LDSNPsAdd.csv\"\n",
    "pathLDSNPOne = relSNPPath + \"LDSNPsOne.csv\"\n",
    "pathLDSNPTwo = relSNPPath + \"LDSNPsTwo.csv\"\n",
    "pathLDSNPDipGen = relSNPPath + \"LDSNPsDipGen.csv\"\n",
    "pathLDSNPDipAdd = relSNPPath + \"LDSNPsDipAdd.csv\"\n",
    "pathLDSNPGen = relSNPPath + \"LDSNPsGen.csv\"\n",
    "\n",
    "# Creating dictionary of in- and output path pairs\n",
    "pathDict = {\n",
    "    \"Add\": [pathAdd, pathSNPAdd, pathLDSNPAdd],\n",
    "    \"One\": [pathOne, pathSNPOne, pathLDSNPOne],\n",
    "    \"Two\": [pathTwo, pathSNPTwo, pathLDSNPTwo],\n",
    "    \"DipGen\": [pathDipGen, pathSNPDipGen, pathLDSNPDipGen],\n",
    "    \"DipAdd\": [pathDipAdd, pathSNPDipAdd, pathLDSNPDipAdd],\n",
    "    \"Gen\": [pathGen, pathSNPGen, pathLDSNPGen]\n",
    "}\n",
    "\n",
    "# Sorting by score and identify 10 best SNPs and threshold for suggestive line in manhattan plot\n",
    "for key, values in pathDict.items():\n",
    "    # converting in- and output path to absolute path strings\n",
    "    # Input path\n",
    "    inPathString = pathlib.Path(values[0])\n",
    "    inAbsPath = inPathString.resolve(strict=True)\n",
    "    inAbsPath = str(inAbsPath)\n",
    "    # Output paths\n",
    "    outAbsPath = os.path.abspath(values[1])\n",
    "    outAbsPathLD = os.path.abspath(values[2])\n",
    "    # Creating data frame from input file\n",
    "    scoreFrame = pd.read_csv(inAbsPath)\n",
    "\n",
    "    \n",
    "    # All models with only one score column\n",
    "    if values[0] in [pathAdd, pathDipAdd, pathDipGen, pathGen]:\n",
    "        # Sorting the SNPs descending, NAs at the bottom\n",
    "        scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "        # Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "        bestTenThresh = truncate((scoreFrame.iloc[9, 5] + scoreFrame.iloc[10, 5])/2, 2)\n",
    "        print(f\"Threshold for 10 best SNPs in the {list(scoreFrame.columns)[5]} model: {bestTenThresh}\")\n",
    "        # Create best list containing only marker names\n",
    "        bestList = scoreFrame.iloc[:10,0]\n",
    "        bestListTemplate = scoreFrame.iloc[:10]\n",
    "        LDBestList = scoreFrame.iloc[:10]\n",
    "        # Write output of best scoring SNPs for each model to file\n",
    "        with open(outAbsPath, 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(bestList)\n",
    "        \n",
    "        # Determine all valid SNPs in LD and write to output path\n",
    "        for snp in bestListTemplate.iterrows():\n",
    "            # Getting important values of the high-scoring SNP\n",
    "            chrom = snp[1][1]\n",
    "            pos = snp[1][2]\n",
    "            #print(f\"{snp[1][0]} lies on {chrom} at position {pos}\")\n",
    "            window = LDs[chrom] * 10**6\n",
    "            #print(window)\n",
    "            rightMax = pos + window\n",
    "            leftMax = pos - window\n",
    "            # Append prelBestList by every SNP from the list within the same chromosome and within the length of the window\n",
    "            for SNP in scoreFrame.iterrows():\n",
    "                SNPCHROM = SNP[1][1]\n",
    "                SNPPOS = SNP[1][2]\n",
    "                score = SNP[1][5]\n",
    "                # print(f\"{SNP[1][0]} lies on {SNPCHROM} at position {SNPPOS}\")\n",
    "                # Check for position of potentially appendable SNPs\n",
    "                if SNPCHROM == chrom and score != 'nan':\n",
    "                    if SNPPOS <= rightMax and SNPPOS >= leftMax:\n",
    "                        LDBestList = LDBestList.append(scoreFrame.loc[SNP[0]])\n",
    "        # Write all SNPs in LD to output file\n",
    "        markerNames = LDBestList.iloc[:,0]\n",
    "        with open(outAbsPathLD, 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(markerNames)\n",
    "                        \n",
    "    # Simplex and duplex models\n",
    "    else:\n",
    "        scoreSortedAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "        scoreSortedRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)\n",
    "        # Check for lowest score between REF and ALT scores\n",
    "        if truncate(scoreSortedAlt.iloc[4, 5],2) < truncate(scoreSortedRef.iloc[4, 6],2):\n",
    "            bestTenThresh = truncate((scoreSortedAlt.iloc[4, 5] + scoreSortedAlt.iloc[5, 5])/2, 2)\n",
    "        else:\n",
    "            bestTenThresh = truncate((scoreSortedRef.iloc[4, 6] + scoreSortedRef.iloc[5, 6])/2, 2)\n",
    "        print(f\"Threshold for 10 best SNPs in the {list(scoreSortedRef.columns)[5][:5]} model: {bestTenThresh}\")\n",
    "        bestList = scoreSortedAlt.iloc[:5,0].append(scoreSortedRef.iloc[:5,0])\n",
    "        bestListTemplate = scoreSortedAlt.iloc[:5].append(scoreSortedRef.iloc[:5])\n",
    "        LDBestList = scoreSortedAlt.iloc[:5].append(scoreSortedRef.iloc[:5])\n",
    "        #Write output of best SNPs to file\n",
    "        with open(outAbsPath, 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(bestList)\n",
    "\n",
    "        # Determine all valid SNPs in LD and write to output path\n",
    "        for snp in bestListTemplate.iterrows():\n",
    "            # Checking, if SNP has scored as ALT or REF model for getting LD SNPs that possess scores\n",
    "            if snp[1][5] != 'nan':\n",
    "                ALT = True\n",
    "            else:\n",
    "                ALT = False\n",
    "            # Getting important values of the high-scoring SNP\n",
    "            chrom = snp[1][1]\n",
    "            pos = snp[1][2]\n",
    "            #print(f\"{snp[1][0]} lies on {chrom} at position {pos}\")\n",
    "            window = LDs[chrom] * 10**6\n",
    "            #print(window)\n",
    "            rightMax = pos + window\n",
    "            leftMax = pos - window\n",
    "            # Append prelBestList by every SNP from the list within the same chromosome and within the length of the window\n",
    "            for SNP in scoreFrame.iterrows():\n",
    "                SNPCHROM = SNP[1][1]\n",
    "                SNPPOS = SNP[1][2]\n",
    "                if ALT == True:\n",
    "                    score = SNP[1][5]\n",
    "                else:\n",
    "                    score = SNP[1][6]\n",
    "                #print(f\"{SNP[1][0]} lies on {SNPCHROM} at position {SNPPOS}\")\n",
    "                # Check for position of potentially appendable SNPs\n",
    "                if SNPCHROM == chrom and score != 'nan':\n",
    "                    if SNPPOS <= rightMax and SNPPOS >= leftMax:\n",
    "                        LDBestList = LDBestList.append(scoreFrame.loc[SNP[0]])\n",
    "        # Write all SNPs in LD to output file\n",
    "        markerNames = LDBestList.iloc[:,0]\n",
    "        with open(outAbsPathLD, 'w', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=',')\n",
    "            writer.writerow(markerNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving table with best SNPs and additional info for MA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDlower(pos, chrom):\n",
    "    # Define LD for each chromosome as a dictionary\n",
    "    LDs = {\"chr01\": 0.89,\n",
    "           \"chr02\": 1.05,\n",
    "           \"chr03\": 1.14,\n",
    "           \"chr04\": 0.86,\n",
    "           \"chr05\": 0.70,\n",
    "           \"chr06\": 1.11,\n",
    "           \"chr07\": 0.82,\n",
    "           \"chr08\": 0.93,\n",
    "           \"chr09\": 0.67,\n",
    "           \"chr10\": 0.96,\n",
    "           \"chr11\": 0.71,\n",
    "           \"chr12\": 0.66}\n",
    "    \n",
    "    realLD = LDs[chrom]*10**6\n",
    "    lower = pos - realLD\n",
    "    if lower < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return lower\n",
    "\n",
    "def LDupper(pos, chrom):\n",
    "    # Define LD for each chromosome as a dictionary\n",
    "    LDs = {\"chr01\": 0.89,\n",
    "           \"chr02\": 1.05,\n",
    "           \"chr03\": 1.14,\n",
    "           \"chr04\": 0.86,\n",
    "           \"chr05\": 0.70,\n",
    "           \"chr06\": 1.11,\n",
    "           \"chr07\": 0.82,\n",
    "           \"chr08\": 0.93,\n",
    "           \"chr09\": 0.67,\n",
    "           \"chr10\": 0.96,\n",
    "           \"chr11\": 0.71,\n",
    "           \"chr12\": 0.66}\n",
    "    # Define chromosome lengths (according to reference genome) for preventing surpassing chromosome boundaries\n",
    "    lengths = {\n",
    "        \"chr01\": 88663952,\n",
    "        \"chr02\": 48614681,\n",
    "        \"chr03\": 62290286,\n",
    "        \"chr04\": 72208621,\n",
    "        \"chr05\": 52070158,\n",
    "        \"chr06\": 59532096,\n",
    "        \"chr07\": 56760843,\n",
    "        \"chr08\": 56938457,\n",
    "        \"chr09\": 61540751,\n",
    "        \"chr10\": 59756223,\n",
    "        \"chr11\": 45475667,\n",
    "        \"chr12\": 61165649\n",
    "    }\n",
    "    realLD = LDs[chrom]*10**6\n",
    "    upper = pos + realLD\n",
    "    if upper > lengths[chrom]:\n",
    "        return lengths[chrom]\n",
    "    else:\n",
    "        return upper   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestTenAdd['Position'][24042]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = LD(bestTenAdd['Position'][24042], bestTenAdd['Chrom'][24042])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bestTenAdd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#                                          #\n",
    "# Reading the score files for all 6 models #\n",
    "#                                          #\n",
    "############################################\n",
    "\n",
    "# Relative input string for the pandas module\n",
    "relPathString = \"../../data/GWAS_results/\"\n",
    "pathAdd = relPathString + \"scoresAdd.csv\"\n",
    "pathOne = relPathString + \"scoresOne.csv\"\n",
    "pathTwo = relPathString + \"scoresTwo.csv\"\n",
    "pathDipGen = relPathString + \"scoresDipGen.csv\"\n",
    "pathDipAdd = relPathString + \"scoresDipAdd.csv\"\n",
    "pathGen = relPathString + \"scoresGen.csv\"\n",
    "\n",
    "\n",
    "##################\n",
    "#                #\n",
    "# Additive model #\n",
    "#                #\n",
    "##################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathAdd)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "bestTenThreshAdd = truncate((scoreFrame.iloc[9, 5] + scoreFrame.iloc[10, 5])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrame.columns)[5]} model: {bestTenThreshAdd}\")\n",
    "# Create data frame with 10 best SNPs and additional information\n",
    "bestTenAdd = scoreFrame.iloc[:10,]\n",
    "bestTenAdd['Model'] = list(bestTenAdd.columns)[5]\n",
    "bestTenAdd = bestTenAdd.rename(columns={\"additive\":\"Score\"})\n",
    "bestTenAdd['Score'] = bestTenAdd.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenAdd['LD-lower'] = bestTenAdd.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenAdd['LD-upper'] = bestTenAdd.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "\n",
    "#################\n",
    "#               #\n",
    "# Simplex model #\n",
    "#               #\n",
    "#################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathOne)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrameAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "scoreFrameRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)\n",
    "\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "if truncate(scoreFrameAlt.iloc[4, 5],2) < truncate(scoreFrameRef.iloc[4, 6],2):\n",
    "    bestTenThresh = truncate((scoreFrameAlt.iloc[4, 5] + scoreFrameAlt.iloc[5, 5])/2, 2)\n",
    "else:\n",
    "    bestTenThresh = truncate((scoreFrameRef.iloc[4, 6] + scoreFrameRef.iloc[5, 6])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrameRef.columns)[5][:5]} model: {bestTenThresh}\")\n",
    "# First for the alternative dominant model\n",
    "bestTenOneAlt = scoreFrameAlt.iloc[:5,]\n",
    "bestTenOneAlt['Model'] = list(bestTenOneAlt.columns)[5]\n",
    "bestTenOneAlt = bestTenOneAlt.rename(columns={\"1-dom-alt\":\"Score\"})\n",
    "bestTenOneAlt['Score'] = bestTenOneAlt.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenOneAlt['LD-lower'] = bestTenOneAlt.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenOneAlt['LD-upper'] = bestTenOneAlt.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "# Then for the reference dominant model\n",
    "bestTenOneRef = scoreFrameRef.iloc[:5,]\n",
    "bestTenOneRef['Model'] = list(bestTenOneRef.columns)[6]\n",
    "bestTenOneRef = bestTenOneRef.rename(columns={\"1-dom-ref\":\"Score\"})\n",
    "bestTenOneRef['Score'] = bestTenOneRef.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenOneRef['LD-lower'] = bestTenOneRef.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenOneRef['LD-upper'] = bestTenOneRef.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "# Concatenating both models\n",
    "bestTenOne = pd.concat([bestTenOneAlt, bestTenOneRef])\n",
    "\n",
    "\n",
    "################\n",
    "#              #\n",
    "# Duplex model #\n",
    "#              #\n",
    "################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathTwo)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrameAlt = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "scoreFrameRef = scoreFrame.sort_values(by=[list(scoreFrame.columns)[6]], ascending=False)\n",
    "\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "if truncate(scoreFrameAlt.iloc[4, 5],2) < truncate(scoreFrameRef.iloc[4, 6],2):\n",
    "    bestTenThresh = truncate((scoreFrameAlt.iloc[4, 5] + scoreFrameAlt.iloc[5, 5])/2, 2)\n",
    "else:\n",
    "    bestTenThresh = truncate((scoreFrameRef.iloc[4, 6] + scoreFrameRef.iloc[5, 6])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrameRef.columns)[5][:5]} model: {bestTenThresh}\")\n",
    "# Create data frame with 10 best SNPs and additional information\n",
    "# First for the alternative dominant model\n",
    "bestTenTwoAlt = scoreFrameAlt.iloc[:5,]\n",
    "bestTenTwoAlt['Model'] = list(bestTenTwoAlt.columns)[5]\n",
    "bestTenTwoAlt = bestTenTwoAlt.rename(columns={\"2-dom-alt\":\"Score\"})\n",
    "bestTenTwoAlt['Score'] = bestTenTwoAlt.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenTwoAlt['LD-lower'] = bestTenTwoAlt.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenTwoAlt['LD-upper'] = bestTenTwoAlt.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "# Then for the reference dominant model\n",
    "bestTenTwoRef = scoreFrameRef.iloc[:5,]\n",
    "bestTenTwoRef['Model'] = list(bestTenTwoRef.columns)[6]\n",
    "bestTenTwoRef = bestTenTwoRef.rename(columns={\"2-dom-ref\":\"Score\"})\n",
    "bestTenTwoRef['Score'] = bestTenTwoRef.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenTwoRef['LD-lower'] = bestTenTwoRef.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenTwoRef['LD-upper'] = bestTenTwoRef.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "# Concatenating both models\n",
    "bestTenTwo = pd.concat([bestTenTwoAlt, bestTenTwoRef])\n",
    "\n",
    "\n",
    "#########################\n",
    "#                       #\n",
    "# Diploid general model #\n",
    "#                       #\n",
    "#########################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathDipGen)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "bestTenThresh = truncate((scoreFrame.iloc[9, 5] + scoreFrame.iloc[10, 5])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrame.columns)[5]} model: {bestTenThresh}\")\n",
    "# Create data frame with 10 best SNPs and additional information\n",
    "bestTenDipGen = scoreFrame.iloc[:10,]\n",
    "bestTenDipGen['Model'] = list(bestTenDipGen.columns)[5]\n",
    "bestTenDipGen = bestTenDipGen.rename(columns={\"diplo-general\":\"Score\"})\n",
    "bestTenDipGen['Score'] = bestTenDipGen.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenDipGen['LD-lower'] = bestTenDipGen.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenDipGen['LD-upper'] = bestTenDipGen.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "\n",
    "\n",
    "##########################\n",
    "#                        #\n",
    "# Diploid additive model #\n",
    "#                        #\n",
    "##########################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathDipAdd)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "bestTenThresh = truncate((scoreFrame.iloc[9, 5] + scoreFrame.iloc[10, 5])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrame.columns)[5]} model: {bestTenThresh}\")\n",
    "# Create data frame with 10 best SNPs and additional information\n",
    "bestTenDipAdd = scoreFrame.iloc[:10,]\n",
    "bestTenDipAdd['Model'] = list(bestTenDipAdd.columns)[5]\n",
    "bestTenDipAdd = bestTenDipAdd.rename(columns={\"diplo-additive\":\"Score\"})\n",
    "bestTenDipAdd['Score'] = bestTenDipAdd.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenDipAdd['LD-lower'] = bestTenDipAdd.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenDipAdd['LD-upper'] = bestTenDipAdd.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "\n",
    "#################\n",
    "#               #\n",
    "# General model #\n",
    "#               #\n",
    "#################\n",
    "\n",
    "# converting in- and output path to absolute path strings\n",
    "inPathString = pathlib.Path(pathGen)\n",
    "inAbsPath = inPathString.resolve(strict=True)\n",
    "inAbsPath = str(inAbsPath)\n",
    "# Creating data frame from input file\n",
    "scoreFrame = pd.read_csv(inAbsPath)\n",
    "scoreFrame = scoreFrame.sort_values(by=[list(scoreFrame.columns)[5]], ascending=False)\n",
    "# Find and print the suggested threshold between 10th and 11th best ranking SNPs\n",
    "bestTenThresh = truncate((scoreFrame.iloc[9, 5] + scoreFrame.iloc[10, 5])/2, 2)\n",
    "print(f\"Threshold for 10 best SNPs in the {list(scoreFrame.columns)[5]} model: {bestTenThresh}\")\n",
    "# Create data frame with 10 best SNPs and additional information\n",
    "bestTenGen = scoreFrame.iloc[:10,]\n",
    "bestTenGen['Model'] = list(bestTenGen.columns)[5]\n",
    "bestTenGen = bestTenGen.rename(columns={\"general\":\"Score\"})\n",
    "bestTenGen['Score'] = bestTenGen.apply(lambda x: truncate(x['Score'], 2), axis=1)\n",
    "bestTenGen['LD-lower'] = bestTenGen.apply(lambda x: LDlower(x['Position'], x['Chrom']), axis=1)\n",
    "bestTenGen['LD-upper'] = bestTenGen.apply(lambda x: LDupper(x['Position'], x['Chrom']), axis=1)\n",
    "\n",
    "bigFrame = pd.concat([bestTenAdd, bestTenOne, bestTenTwo, bestTenDipGen, bestTenDipAdd, bestTenGen])\n",
    "bigFrame = bigFrame.iloc[:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigFrame.sort_values(by=[list(bigFrame.columns)[1], list(bigFrame.columns)[2]], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigFrame['Marker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestTenGen.sort_values(by=[list(bestTenGen.columns)[1], list(bestTenGen.columns)[2]], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying candidate genes from the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 'high scoring clusters'\n",
    "# Key is cluster name, values are chromosome, start, and end of the clusters\n",
    "clusters = pd.DataFrame({\n",
    "    'Name':['chr01.1', 'chr01.2', 'chr01.3', 'chr02.1', 'chr02.2', 'chr02.3', 'chr02.4', 'chr02.5', 'chr03.1', 'chr03.2', 'chr07.1', 'chr09.1', 'chr09.2', 'chr09.3', 'chr09.4', 'chr10.1', 'chr10.2', 'chr11.1', 'chr12.1', 'chr12.2', 'chr12.3', 'chr12.4']\n",
    "    \n",
    "})\n",
    "# Defining function for chromosome names and appending the data frame by it\n",
    "def chrom(string):\n",
    "    return string[:5]\n",
    "clusters['Chromosome'] = clusters.apply(lambda x: chrom(x['Name']), axis=1)\n",
    "\n",
    "# Appending start and end of the clusters\n",
    "clusters['Start'] = [42240780, 66206226, 67554192, 24815002, 27617140, 37655544, 42028257, 43512360, 45083029, 51893032, 52226902, 4882536, 5819191, 53405466, 54899227, 49070040, 53903541, 42632639, 750038, 58560145, 59432597, 60343136]\n",
    "clusters['End'] = [44020780, 68228593, 69510680, 26915002, 30659098, 39755544, 44128257, 45612361, 47363029, 54173032, 53866902, 6266242, 7780360, 54745466, 56467680, 50990040, 55823541, 44052639, 2070038, 59880145, 60752597, 61165649]\n",
    "clusters['Length'] = clusters['End'] - clusters['Start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing starch-related genes and transcripts from [Van Harsselaar et al., 2017] (https://doi.org/10.1186/s12864-016-3381-z)\n",
    "starchGenes = [\n",
    "    ['PGSC0003DMG400009026', 'PGSC0003DMT400023304', 'ADP-glucose pyrophosphorylaselarge subunit 1 (AGPL1)'],\n",
    "    ['PGSC0003DMG400015952', 'PGSC0003DMT400041215', 'ADP-glucose pyrophosphorylaselarge subunit 2 (AGPL2)'],\n",
    "    ['PGSC0003DMG400000735', 'PGSC0003DMT400001935', 'ADP-glucose pyrophosphorylaselarge subunit 3 (AGPL3)'],\n",
    "    ['PGSC0003DMG400031084', 'PGSC0003DMT400079823', 'ADP-glucose pyrophosphorylasesmall subunit 1.1 (AGPS1.1)'],\n",
    "    ['PGSC0003DMG400046891', 'PGSC0003DMT400097320', 'ADP-glucose pyrophosphorylasesmall subunit 1.2 (AGPS1.2)'],\n",
    "    ['PGSC0003DMG400025218', 'PGSC0003DMT400064936', 'ADP-glucose pyrophosphorylasesmall subunit 2 (AGPS2)'],\n",
    "    ['PGSC0003DMG400007974', 'PGSC0003DMT400020591', 'Alpha-amylase 1.1 (AMY1.1)'],\n",
    "    ['PGSC0003DMG400020603', 'PGSC0003DMT400053110', 'Alpha-amylase 1.2 (AMY1.2)'],\n",
    "    ['PGSC0003DMG400009891', 'PGSC0003DMT400025601', 'Alpha-amylase 2 (AMY23)'],\n",
    "    ['PGSC0003DMG401017626', 'PGSC0003DMT400045435', 'Alpha-amylase 3 (AMY3)'],\n",
    "    ['PGSC0003DMG400007782', 'PGSC0003DMT400020094', 'Alpha-glucan phosphorylase 1a(PHO1a)'],\n",
    "    ['PGSC0003DMG400003495', 'PGSC0003DMT400008970', 'Alpha-glucan phosphorylase 1a(PHO1a)'],\n",
    "    ['PGSC0003DMG400002479', 'PGSC0003DMT400006337', 'Alpha-glucan phosphorylase 1a(PHO1a)'],\n",
    "    ['PGSC0003DMG400028382', 'PGSC0003DMT400072963', 'Alpha-glucan phosphorylase 1b(PHO1b)'],\n",
    "    ['PGSC0003DMG400031765', 'PGSC0003DMT400081273', 'Alpha-glucan phosphorylase 2b(PHO2b)'],\n",
    "    ['PGSC0003DMG400005612', 'PGSC0003DMT400014304', 'ATP-ADP antiporter 1 (NTT1)'],\n",
    "    ['PGSC0003DMG400028641', 'PGSC0003DMT400073724', 'ATP-ADP antiporter 2 (NTT2)'],\n",
    "    ['PGSC0003DMG400001549', 'PGSC0003DMT400003933', 'Beta-amylase 1 (BAM1)'],\n",
    "    ['PGSC0003DMG400024145', 'PGSC0003DMT400062050', 'Beta-amylase 2 (BAM2)'],\n",
    "    ['PGSC0003DMG400001855', 'PGSC0003DMT400004686', 'Beta-amylase 3.1 (BAM3.1)'],\n",
    "    ['PGSC0003DMG402020509', 'PGSC0003DMT400052839', 'Beta-amylase 3.2 (BAM3.2)'],\n",
    "    ['PGSC0003DMG400012129', 'PGSC0003DMT400031627', 'Beta-amylase 4 (BAM4)'],\n",
    "    ['PGSC0003DMG400026199', 'PGSC0003DMT400067403', 'Beta-amylase 6.1 (BAM6.1)'],\n",
    "    ['PGSC0003DMG400026166', 'PGSC0003DMT400067289', 'Beta-amylase 6.2 (BAM6.2)'],\n",
    "    ['PGSC0003DMG400026198', 'PGSC0003DMT400067400', 'Beta-amylase 6.3 (BAM6.3)'],\n",
    "    ['PGSC0003DMG400000169', 'PGSC0003DMT400000485', 'Beta-amylase 7 (BAM7)'],\n",
    "    ['PGSC0003DMG400010664', 'PGSC0003DMT400027659', 'Beta-amylase 9 (BAM9)'],\n",
    "    ['PGSC0003DMG400022307', 'PGSC0003DMT400057446', 'Branching enzyme I.1 (SBE1.1)'],\n",
    "    ['PGSC0003DMG400009981', 'PGSC0003DMT400025846', 'Branching enzyme III (SBE3)'],\n",
    "    ['PGSC0003DMG400016589', 'PGSC0003DMT400042739', 'Disproportionating enzyme 1 (DPE1)'],\n",
    "    ['PGSC0003DMG400007677', 'PGSC0003DMT400019845', 'Glucan water dikinase (GWD)'],\n",
    "    ['PGSC0003DMG400026402', 'PGSC0003DMT400067884', 'Glucose transporter (GLT1)'],\n",
    "    ['PGSC0003DMG400001041', 'PGSC0003DMT400002701', 'Glucose-6-phosphate translocator 1.1(GPT1.1)'],\n",
    "    ['PGSC0003DMG400005602', 'PGSC0003DMT400014284', 'Glucose-6-phosphate translocator 1.1(GPT1.1)'],\n",
    "    ['PGSC0003DMG400005269', 'PGSC0003DMT400013500', 'Glucose-6-phosphate translocator 2.1(GPT2.1)'],\n",
    "    ['PGSC0003DMG400025495', 'PGSC0003DMT400065527', 'Glucose-6-phosphate translocator 2.2(GPT2.2)'],\n",
    "    ['PGSC0003DMG400012111', 'PGSC0003DMT400031568', 'Granule bound starch synthase 1(GBSS1)'],\n",
    "    ['PGSC0003DMG400003103', 'PGSC0003DMT400008028', 'Inorganic pyrophosphatase (PPase)'],\n",
    "    ['PGSC0003DMG400026784', 'PGSC0003DMT400068875', 'Inorganic pyrophosphatase-like(PPase-like)'],\n",
    "    ['PGSC0003DMG400020699', 'PGSC0003DMT400053345', 'Isoamylase 1.1 (ISA1.1)'],\n",
    "    ['PGSC0003DMG400030253', 'PGSC0003DMT400077770', 'Isoamylase 1.2 (ISA 1.2)'],\n",
    "    ['PGSC0003DMG400000954', 'PGSC0003DMT400002502', 'Isoamylase 2 (ISA2)'],\n",
    "    ['PGSC0003DMG402007274', 'PGSC0003DMT400018766', 'Isoamylase 3 (ISA3)'],\n",
    "    ['PGSC0003DMG401007274', 'PGSC0003DMT400018765', 'Isoamylase 3 (ISA3)'],\n",
    "    ['PGSC0003DMG400024812', 'PGSC0003DMT400063824', 'Maltose excess 1 (MEX1)'],\n",
    "    ['PGSC0003DMG400030092', 'PGSC0003DMT400077364', 'Phosphoglucan phosphatase(like SEX four 1, LSF1)'],\n",
    "    ['PGSC0003DMG400029073', 'PGSC0003DMT400074765', 'Phosphoglucan phosphatase(like SEX four 2, LSF2)'],\n",
    "    ['PGSC0003DMG400015246', 'PGSC0003DMT400039423', 'Phosphoglucan phosphatase (SEX4)'],\n",
    "    ['PGSC0003DMG400027327', 'PGSC0003DMT400070294', 'Phosphoglucan phosphatase(SEX4-like)'],\n",
    "    ['PGSC0003DMG400016613', 'PGSC0003DMT400042818', 'Phosphoglucan water dikinase(PWD)'],\n",
    "    ['PGSC0003DMG400012910', 'PGSC0003DMT400033620', 'Phosphoglucoisomerase (PGI)'],\n",
    "    ['PGSC0003DMG400015341', 'PGSC0003DMT400039665', 'Phosphoglucoisomerase-like 1(PGI-like1)'],\n",
    "    ['PGSC0003DMG400030128', 'PGSC0003DMT400077470', 'Phosphoglucoisomerase-like 2(PGI-like2)'],\n",
    "    ['PGSC0003DMG402018552', 'PGSC0003DMT400047731', 'Starch Synthase I (SS1)'],\n",
    "    ['PGSC0003DMG400001328', 'PGSC0003DMT400003356', 'Starch Synthase II (SS2)'],\n",
    "    ['PGSC0003DMG400016481', 'PGSC0003DMT400042496', 'Starch Synthase III (SS3)'],\n",
    "    ['PGSC0003DMG400008322', 'PGSC0003DMT400021444', 'Starch Synthase IV (SS4)'],\n",
    "    ['PGSC0003DMG400030619', 'PGSC0003DMT400078688', 'Starch Synthase V (SS5)'],\n",
    "    ['PGSC0003DMG402013540', 'PGSC0003DMT400035218', 'Starch Synthase VI (SS6)'],\n",
    "    ['PGSC0003DMG400013547', 'PGSC0003DMT400035264', 'Sucrose Synthase 1 (SuSy1)'],\n",
    "    ['PGSC0003DMG400013546', 'PGSC0003DMT400035262', 'Sucrose Synthase 2 (SuSy2)'],\n",
    "    ['PGSC0003DMG400006672', 'PGSC0003DMT400017087', 'Sucrose Synthase 3 (SuSy3)'],\n",
    "    ['PGSC0003DMG400002895', 'PGSC0003DMT400007506', 'Sucrose Synthase 4 (SuSy4)'],\n",
    "    ['PGSC0003DMG400031046', 'PGSC0003DMT400079728', 'Sucrose Synthase 6 (SuSy6)'],\n",
    "    ['PGSC0003DMG400016730', 'PGSC0003DMT400043117', 'Sucrose Synthase 7 (SuSy7)'],\n",
    "    ['PGSC0003DMG400022832', 'PGSC0003DMT400058772', 'Triose-phosphate/phosphatetranslocator (TPT)'],\n",
    "    ['PGSC0003DMG401013333', 'PGSC0003DMT400034699', 'UDP-glucose pyrophosphorylase 2(UGPase2)'],\n",
    "    ['PGSC0003DMG401010374', 'PGSC0003DMT400026885', 'Vacuolar Glucose Transporter 3-like(VGT3-like)']\n",
    "]\n",
    "\n",
    "# Extracting the identifiers for identifying starch genes in GFF3 file\n",
    "PGSCs = [gene[0] for gene in starchGenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating in- and output file names\n",
    "inPath = \"../../data/Reference_genome_and_annotation_file/pgsc_unducked.gff\"\n",
    "\n",
    "# Create absolute path and read the file\n",
    "absInPath = os.path.abspath(inPath)\n",
    "gffFile = gffpd.read_gff3(absInPath)\n",
    "\n",
    "# Extracting only the genes\n",
    "gffFileGenes = gffFile.df[gffFile.df['type'] == 'gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gffFile.df[gffFile.df['type'] == 'gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IDextract(attrString):\n",
    "    IDString = attrString.split(';')[0]\n",
    "    geneID = IDString.split('=')[1]\n",
    "    return geneID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate empty lists \n",
    "# numGenes = []\n",
    "for cluster in clusters.iterrows():\n",
    "    chrom = cluster[1][1]\n",
    "    start = cluster[1][2]\n",
    "    end = cluster[1][3]\n",
    "    # Extracting genes only belonging to the chromosome and region of interest \n",
    "    gffFileGenesSub = gffFileGenes[(gffFileGenes['seq_id'] == chrom) & (gffFileGenes['start'] >= start) & (gffFileGenes['end'] <= end)]\n",
    "    # Testing the lengths\n",
    "    #print(gffFileGenesSub.shape[0])\n",
    "    #print(gffFileGenesSub.head(n = 5))\n",
    "    # Extract the number of genes in each cluster\n",
    "    #numGenes.append(gffFileGenesSub.shape[0])\n",
    "    #print(gffFileGenesSub['attributes'])\n",
    "    # Create new data frame column containing only the gene IDs for filtering starch genes\n",
    "    gffFileGenesSub['geneID'] = gffFileGenesSub.apply(lambda x: IDextract(x['attributes']), axis=1)\n",
    "    #print(gffFileGenesSub.head(n = 5))\n",
    "    #print(gffFileGenesSub['geneID'] in PGSCs)\n",
    "    gffFileGenesSubStarch = gffFileGenesSub[gffFileGenesSub['geneID'].isin (PGSCs)]\n",
    "    print(cluster[1][0])\n",
    "    print(gffFileGenesSubStarch.shape)\n",
    "    print(gffFileGenesSubStarch, '\\n')\n",
    "    #clusters['numGenes'] = numGenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['GenperMB'] = clusters['numGenes'] / (clusters['Length']/10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters['Length']/(10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting some basic stats from the GFF3 file\n",
    "# Creating in- and output file names\n",
    "inPath = \"../../data/Reference_genome_and_annotation_file/pgsc_unducked.gff\"\n",
    "\n",
    "# Create absolute path and read the file\n",
    "absInPath = os.path.abspath(inPath)\n",
    "\n",
    "examiner = GFFExaminer()\n",
    "in_handle = open(absInPath)\n",
    "pprint.pprint(examiner.available_limits(in_handle))\n",
    "in_handle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
